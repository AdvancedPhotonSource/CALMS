{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1'\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#Need only 1 GPU if loading 8-bit model\n",
    "print(device)\n",
    "\n",
    "print(\"Using %d GPUs\" %torch.cuda.device_count())\n",
    "\n",
    "import gradio as gr\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"eachadea/vicuna-13b-1.1\"\n",
    "tokenizer_path = \"./tokenizer/\"\n",
    "\n",
    "#Create a local tokenizer copy the first time\n",
    "if os.path.isdir(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"model_name\")\n",
    "    os.mkdir(tokenizer_path)\n",
    "    tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1911acba940543a7ac30b2ffab49495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")#, load_in_8bit=True)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load embedding model and use that to embed text from source\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "with open(\"APS-Science-Highlight/2021-07-06_better-educated-neural-networks-for-nanoscale-3-d-coherent-x-ray.txt\") as f:\n",
    "    book = f.read()\n",
    "\n",
    "#print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "texts = text_splitter.split_text(book)\n",
    "docsearch = Chroma.from_texts(\n",
    "    texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query):\n",
    "    N_hits = 3 #How many hits of context to provide?\n",
    "    docs = docsearch.similarity_search_with_score(query, k=N_hits)\n",
    "    #Get context strings\n",
    "    context=\"\"\n",
    "    for i in range(N_hits):\n",
    "        context += docs[i][0].page_content +\"\\n\"\n",
    "    #print (context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"history\", \n",
    "                                        input_key = \"input\", \n",
    "                                        k=6)\n",
    "\n",
    "\n",
    "conversation = LLMChain(\n",
    "        prompt=PROMPT,\n",
    "        llm=local_llm, \n",
    "        verbose=True, \n",
    "        memory=memory\n",
    ")\n",
    "\n",
    "#print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(css=\"footer {visibility: hidden}\", title=\"APS ChatBot\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # Welcome to the APS AI Assistant!\n",
    "    Start typing below to see the output.\n",
    "    \"\"\"\n",
    "    )\n",
    "    chatbot = gr.Chatbot(show_label=False).style(height=\"500\")\n",
    "    msg = gr.Textbox(label=\"Send a message with Enter\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "\n",
    "        user_message = history[-1][0] #History is list of tuple list. E.g. : [['Hi', 'Test'], ['Hello again', '']]\n",
    "        bot_message = conversation.predict(input=user_message, context=get_context(user_message))\n",
    "        #Pass user message and get context and pass to model\n",
    "        history[-1][1] = \"\" #Replaces None with empty string -- Gradio code\n",
    "\n",
    "        for character in bot_message:\n",
    "            history[-1][1] += character\n",
    "            time.sleep(0.02)\n",
    "            yield history\n",
    "    \n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: memory.clear(), None, chatbot, queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:2023\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:2023/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is 3DCDINN?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The U.S. Department of Energy's APS is one of the world’s most productive x-ray light source facilities. Each year, the APS provides high-brightness x-ray beams to a diverse community of more than 5,000 researchers in materials science, chemistry, condensed matter physics, the life and environmental sciences, and applied research. Researchers using the APS produce over 2,000 publications each year detailing impactful discoveries, and solve more vital biological protein structures than users of any other x-ray light source research facility. APS x-rays are ideally suited for explorations of materials and biological structures; elemental distribution; chemical, magnetic, electronic states; and a wide range of technologically important engineering systems from batteries to fuel injector sprays, all of which are the foundations of our nation’s economic, technological, and physical well-being.\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The U.S. Department of Energy's APS is one of the world’s most productive x-ray light source facilities. Each year, the APS provides high-brightness x-ray beams to a diverse community of more than 5,000 researchers in materials science, chemistry, condensed matter physics, the life and environmental sciences, and applied research. Researchers using the APS produce over 2,000 publications each year detailing impactful discoveries, and solve more vital biological protein structures than users of any other x-ray light source research facility. APS x-rays are ideally suited for explorations of materials and biological structures; elemental distribution; chemical, magnetic, electronic states; and a wide range of technologically important engineering systems from batteries to fuel injector sprays, all of which are the foundations of our nation’s economic, technological, and physical well-being.\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 3DCDINN?\n",
      "AI:  3D-CDI-NN stands for three-dimensional coherent diffractive imaging using neural networks. It's a deep learning method used to reconstruct images of nanostructures based on their diffraction patterns.\n",
      "Human: Who are the people involved?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The authors gratefully acknowledge the computing resources provided and operated by the Joint Laboratory for System Evaluation (JLSE) at Argonne National Laboratory. This work was performed at the Center for Nanoscale Materials (CNM) and the APS, both Office of Science user facilities supported by the U.S. Department of (DOE) Office of Science-Basic Energy Sciences, under Contract No. DE-AC02- 06CH11357. This work was also supported by Argonne LDRD 2018-019-N0: A.I C.D.I: Atomistically Informed Coherent Diffraction Imaging and by the U.S. DOE Office of Science-Basic Energy Sciences Data, Artificial Intelligence and Machine Learning at DOE Scientific User Facilities program under Award Number 34532. Development of the automatic differentiation refinement was supported by the U.S. DOE Office of Science-Basic Energy Sciences, Materials Science and Engineering Division. An award of computer time was provided by the Innovative and Novel Computational Impact on Theory and Experiment (INCITE) program.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The authors gratefully acknowledge the computing resources provided and operated by the Joint Laboratory for System Evaluation (JLSE) at Argonne National Laboratory. This work was performed at the Center for Nanoscale Materials (CNM) and the APS, both Office of Science user facilities supported by the U.S. Department of (DOE) Office of Science-Basic Energy Sciences, under Contract No. DE-AC02- 06CH11357. This work was also supported by Argonne LDRD 2018-019-N0: A.I C.D.I: Atomistically Informed Coherent Diffraction Imaging and by the U.S. DOE Office of Science-Basic Energy Sciences Data, Artificial Intelligence and Machine Learning at DOE Scientific User Facilities program under Award Number 34532. Development of the automatic differentiation refinement was supported by the U.S. DOE Office of Science-Basic Energy Sciences, Materials Science and Engineering Division. An award of computer time was provided by the Innovative and Novel Computational Impact on Theory and Experiment (INCITE) program.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 3DCDINN?\n",
      "AI:  3D-CDI-NN stands for three-dimensional coherent diffractive imaging using neural networks. It's a deep learning method used to reconstruct images of nanostructures based on their diffraction patterns.\n",
      "Human: Who are the people involved?\n",
      "AI:  The research team consisted of scientists from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University.\n",
      "Human: What are their names?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is 3DCDINN?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The U.S. Department of Energy's APS is one of the world’s most productive x-ray light source facilities. Each year, the APS provides high-brightness x-ray beams to a diverse community of more than 5,000 researchers in materials science, chemistry, condensed matter physics, the life and environmental sciences, and applied research. Researchers using the APS produce over 2,000 publications each year detailing impactful discoveries, and solve more vital biological protein structures than users of any other x-ray light source research facility. APS x-rays are ideally suited for explorations of materials and biological structures; elemental distribution; chemical, magnetic, electronic states; and a wide range of technologically important engineering systems from batteries to fuel injector sprays, all of which are the foundations of our nation’s economic, technological, and physical well-being.\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n",
      "The U.S. Department of Energy's APS is one of the world’s most productive x-ray light source facilities. Each year, the APS provides high-brightness x-ray beams to a diverse community of more than 5,000 researchers in materials science, chemistry, condensed matter physics, the life and environmental sciences, and applied research. Researchers using the APS produce over 2,000 publications each year detailing impactful discoveries, and solve more vital biological protein structures than users of any other x-ray light source research facility. APS x-rays are ideally suited for explorations of materials and biological structures; elemental distribution; chemical, magnetic, electronic states; and a wide range of technologically important engineering systems from batteries to fuel injector sprays, all of which are the foundations of our nation’s economic, technological, and physical well-being.\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 3DCDINN?\n",
      "AI:  3D-CDI-NN stands for three-dimensional coherent diffractive imaging using neural networks. It's a deep learning method used to reconstruct images of nanostructures based on their diffraction patterns.\n",
      "Human: Who are the people involved?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/responses.py\", line 335, in __call__\n",
      "    stat_result = await anyio.to_thread.run_sync(os.stat, self.path)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/gradio/templates/frontend/assets/js/conf/global_config.js'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 436, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 78, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/fastapi/applications.py\", line 276, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/middleware/cors.py\", line 84, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py\", line 21, in __call__\n",
      "    raise e\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/routing.py\", line 69, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/starlette/responses.py\", line 338, in __call__\n",
      "    raise RuntimeError(f\"File at path {self.path} does not exist.\")\n",
      "RuntimeError: File at path /home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/gradio/templates/frontend/assets/js/conf/global_config.js does not exist.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n",
      "WARNING:  Invalid HTTP request received.\n"
     ]
    }
   ],
   "source": [
    "demo.queue()\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HugFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
