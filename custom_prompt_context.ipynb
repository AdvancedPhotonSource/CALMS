{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beams/MCHERUKARA/miniconda3/envs/HugFace/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1'\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#Need only 1 GPU if loading 8-bit model\n",
    "print(device)\n",
    "\n",
    "print(\"Using %d GPUs\" %torch.cuda.device_count())\n",
    "\n",
    "import gradio as gr\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"eachadea/vicuna-13b-1.1\"\n",
    "tokenizer_path = \"./tokenizer/\"\n",
    "\n",
    "#Create a local tokenizer copy the first time\n",
    "if os.path.isdir(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"model_name\")\n",
    "    os.mkdir(tokenizer_path)\n",
    "    tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11620583cbc14e4092f85224b3250bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")#, load_in_8bit=True)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better-Educated Neural Networks for Nanoscale 3-D Coherent X-ray Imaging\n",
      "\n",
      "One of the inescapable realities of various imaging techniques is called the \"phase problem,\" which simply refers to the loss of phase information inherent in the nature of imaging methods such as x-ray diffraction.  Though it might be inconvenient, it can be dealt with by using various mathematical methods to retrieve the phase data from the image with inverse computation.  Such methods, however, are not only time-consuming but require a great deal of computer power as they must run through multiple iterations to converge on a solution, which prevents real-time imaging.  A group of researchers working at the U.S. Department of Energy’s Advanced Photon Source (APS) has demonstrated a new approach to this perennial obstacle by using a deep-learning neural network trained and optimized for enhanced accuracy to perform fast three-dimensional (3-D) nanoscale imaging from coherent x-ray data.  The work was published in Applied Physics Review.\n",
      "\n",
      "Neural networks, which simulate the operation of the brain's intricate networks of nerve cells for applications such as artificial intelligence, have been criticized because it can be difficult to adequately ‘train’ them for the task at hand.  If the training data or methodology are insufficient, the neural network will fail to perform as desired; as the computer programmer's cliché goes, garbage in, garbage out.  They may also be influenced by subtle biases in the data or may be unable to extrapolate and generalize beyond the limits of their training.             \n",
      "\n",
      "In the present work, the investigators from Argonne National Laboratory, the University of Illinois at Chicago, Stats Perform, and Northwestern University confronted this problem by using explicitly “physics-aware” training that incorporates atomistic simulation data to create diverse training sets based on the physics of the material under study (Fig.1).  The neural network predictions are then further refined in the final stage.  The research team validated this 3-D convolutional encoder-decoder network (3D-CDI-NN) on 3-D coherent x-ray diffraction data of gold nanoparticles performed at the X-ray Science Division Microscopy Group’s 34-ID-C x-ray beamline at the APS.\n",
      "\n",
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "As fourth-generation synchrotron x-ray sources like the upgraded APS come online in the near future, with ever brighter and more versatile beams and capable of generating extremely large datasets, faster and more efficient phase retrieval techniques will be essential.  The research team notes that machine-learning neural network approaches such as 3D-CDI-NN can be trained and improved to surpass traditional phase retrieval techniques by hundreds of times in speed while placing far lesser demands on scarce computing resources.  Such automated methods can also be effectively scaled to different requirements and can even operate on datasets as they are still being collected.\n",
      "\n",
      "Perhaps the phase problem can never be eliminated completely, but neural networks may make it easier to live with.  ― Mark Wolverton\n",
      "\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "\n",
      "The authors gratefully acknowledge the computing resources provided and operated by the Joint Laboratory for System Evaluation (JLSE) at Argonne National Laboratory. This work was performed at the Center for Nanoscale Materials (CNM) and the APS, both Office of Science user facilities supported by the U.S. Department of (DOE) Office of Science-Basic Energy Sciences, under Contract No. DE-AC02- 06CH11357. This work was also supported by Argonne LDRD 2018-019-N0: A.I C.D.I: Atomistically Informed Coherent Diffraction Imaging and by the U.S. DOE Office of Science-Basic Energy Sciences Data, Artificial Intelligence and Machine Learning at DOE Scientific User Facilities program under Award Number 34532. Development of the automatic differentiation refinement was supported by the U.S. DOE Office of Science-Basic Energy Sciences, Materials Science and Engineering Division. An award of computer time was provided by the Innovative and Novel Computational Impact on Theory and Experiment (INCITE) program.\n",
      "\n",
      "The U.S. Department of Energy's APS is one of the world’s most productive x-ray light source facilities. Each year, the APS provides high-brightness x-ray beams to a diverse community of more than 5,000 researchers in materials science, chemistry, condensed matter physics, the life and environmental sciences, and applied research. Researchers using the APS produce over 2,000 publications each year detailing impactful discoveries, and solve more vital biological protein structures than users of any other x-ray light source research facility. APS x-rays are ideally suited for explorations of materials and biological structures; elemental distribution; chemical, magnetic, electronic states; and a wide range of technologically important engineering systems from batteries to fuel injector sprays, all of which are the foundations of our nation’s economic, technological, and physical well-being.\n",
      "\n",
      "Argonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation's first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America's scientific leadership and prepare the nation for a better future. With employees from more than 60 nations, Argonne is managed by UChicago Argonne, LLC, for the U.S. DOE Office of Science.\n",
      "\n",
      "The U.S. Department of Energy's Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit the Office of Science website.\n",
      "\n",
      "Published Date\n",
      "\n",
      "07.06.2021\n"
     ]
    }
   ],
   "source": [
    "#Load embedding model and use that to embed text from source\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "with open(\"APS-Science-Highlight/2021-07-06_better-educated-neural-networks-for-nanoscale-3-d-coherent-x-ray.txt\") as f:\n",
    "    book = f.read()\n",
    "\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(book)\n",
    "docsearch = Chroma.from_texts(\n",
    "    texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.\\xa0 The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.\\xa0 The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns.\\xa0\\n\\nTo enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.\\xa0 This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.', metadata={'source': '4'}), 1.3539000749588013)\n",
      "(Document(page_content='See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\\n\\nAuthor affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\\n\\nCorrespondence: *hchan@anl.gov, **mcherukara@anl.gov', metadata={'source': '7'}), 1.4506618976593018)\n",
      "(Document(page_content='The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles. \\xa0Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.\\xa0 The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.', metadata={'source': '5'}), 1.464565396308899)\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3DCDINN?\"\n",
    "N_hits = 3\n",
    "docs = docsearch.similarity_search_with_score(query, k=N_hits)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get context strings\n",
    "context=\"\"\n",
    "for i in range(N_hits):\n",
    "    context += docs[i][0].page_content +\"\\n\"\n",
    "print (context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"history\", \n",
    "                                        input_key = \"input\", \n",
    "                                        k=6)\n",
    "\n",
    "\n",
    "conversation = LLMChain(\n",
    "        prompt=PROMPT,\n",
    "        llm=local_llm, \n",
    "        verbose=True, \n",
    "        memory=memory\n",
    ")\n",
    "\n",
    "#print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Context:\n",
      "The 3D-CDI-NN model begins with an offline training stage in which polyhedral shapes are created by randomly clipping an fcc crystal lattice structure, applying and relaxing various stresses in the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) molecular dynamics program, and voxelizing the data into a 32 x 32 x 32 voxel grid.  The grid is then entered into 3D-CDI-NN and its predictions matched with the known solutions.  The 3D-CDI-NN framework is quite accurate in its predictions, even when working with under-sampled diffraction patterns. \n",
      "\n",
      "To enhance the accuracy of 3D-CDI-NN even further, the investigators added a refinement that uses a reverse-mode automatic differentiation (AD) technique on the strain predictions and diffraction data.  This proved especially effective in recovering details of structural strain within the examined crystal samples, even when not using oversampled data, as is generally done when using AD techniques.\n",
      "See: Henry Chan1,2*, Youssef S.G. Nashed3, Saugat Kandel4, Stephan O. Hruszkewycz1, Subramanian K.R.S. Sankaranarayanan1,2, Ross J. Harder1, and Mathew J. Cherukara1**, “Rapid 3D Nanoscale Coherent Imaging via Physics-aware Deep Learning,” Appl. Phys. Rev. 8, 021407 (2021). DOI: 10.1063/5.0031486\n",
      "\n",
      "Author affiliations:1Argonne National Laboratory, 2University of Illinois at Chicago, 3Stats Perform, 4Northwestern University\n",
      "\n",
      "Correspondence: *hchan@anl.gov, **mcherukara@anl.gov\n",
      "The researchers demonstrated the effectiveness of the trained 3D-CDI-NN model with real-world data by imaging gold nanoparticles.  Although the initial predictions showed some underestimation of surface details and local strain, which may be due to downsampling of the coherent x-ray data to the 32 x 32 x 32 size, these details were recovered after the AD refinement procedure.  The 3D-CDI-NN framework was demonstrated to be about 4 times faster compared to typical iterative phase retrieval methods.\n",
      "\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is 3DCDINN?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" 3D-CDI-NN stands for three-dimensional coherent diffractive imaging using neural networks. It's a deep learning method used to reconstruct images of nanostructures based on their diffraction patterns.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HugFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
